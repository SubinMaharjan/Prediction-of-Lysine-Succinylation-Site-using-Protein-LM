{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, f1_score\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:12.585445Z","iopub.execute_input":"2023-02-20T03:12:12.585759Z","iopub.status.idle":"2023-02-20T03:12:25.037491Z","shell.execute_reply.started":"2023-02-20T03:12:12.585688Z","shell.execute_reply":"2023-02-20T03:12:25.036531Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# tf.debugging.set_log_device_placement(True)\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth=True\nsess = tf.compat.v1.Session(config=config)\ntf.compat.v1.keras.backend.set_session(sess)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:25.039664Z","iopub.execute_input":"2023-02-20T03:12:25.040361Z","iopub.status.idle":"2023-02-20T03:12:29.641531Z","shell.execute_reply.started":"2023-02-20T03:12:25.040322Z","shell.execute_reply":"2023-02-20T03:12:29.640582Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"window_size = 10\n# def build_model():\n#     model = tf.keras.Sequential([\n#     # data_augmentation,\n#     layers.Conv2D(16, 2, padding='same', activation='relu', input_shape= (2*window_size+1,1024,1)),\n#     layers.MaxPooling2D(),\n#     layers.Conv2D(16, 2, padding='same', activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Flatten(),\n#     layers.Dense(16, activation='relu'),\n#   ])\n#     return model\n\n\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Conv1D(filters = 64, kernel_size = 1,activation='relu', \n                      input_shape= (2*window_size+1,1024), padding=\"same\"))\n#     model.add(layers.MaxPooling1D(pool_size=3))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Conv1D(filters = 128, kernel_size = 1, activation = 'relu'))\n    model.add(layers.MaxPooling1D(pool_size=2))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(8, activation='relu'))\n    return model\n\n\ndef get_model():\n    model1 = build_model()\n    model2 = build_model()\n    model1_model2 = layers.concatenate([model1.output, model2.output], name = \"concatenated_layer\")\n    output_layer = layers.Dense(8, activation='relu')(model1_model2)\n    output_layer = layers.LeakyReLU(alpha=0.3)(output_layer)\n    # output_layer = layers.Dense(16, activation='relu')(output_layer)\n    output_layer = layers.Dropout(0.2)(output_layer)\n    output_layer = layers.Dense(1, activation='sigmoid')(output_layer)\n    model = models.Model(inputs=[model1.input, model2.input], outputs=output_layer, name =\"merged_layers\")\n    return model\n# model = get_model()\n# model.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:29.643296Z","iopub.execute_input":"2023-02-20T03:12:29.643704Z","iopub.status.idle":"2023-02-20T03:12:29.654466Z","shell.execute_reply.started":"2023-02-20T03:12:29.643663Z","shell.execute_reply":"2023-02-20T03:12:29.653485Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:29.657495Z","iopub.execute_input":"2023-02-20T03:12:29.658117Z","iopub.status.idle":"2023-02-20T03:12:29.923221Z","shell.execute_reply.started":"2023-02-20T03:12:29.658078Z","shell.execute_reply":"2023-02-20T03:12:29.922501Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"merged_layers\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n conv1d_input (InputLayer)      [(None, 21, 1024)]   0           []                               \n                                                                                                  \n conv1d_2_input (InputLayer)    [(None, 21, 1024)]   0           []                               \n                                                                                                  \n conv1d (Conv1D)                (None, 21, 64)       65600       ['conv1d_input[0][0]']           \n                                                                                                  \n conv1d_2 (Conv1D)              (None, 21, 64)       65600       ['conv1d_2_input[0][0]']         \n                                                                                                  \n dropout (Dropout)              (None, 21, 64)       0           ['conv1d[0][0]']                 \n                                                                                                  \n dropout_2 (Dropout)            (None, 21, 64)       0           ['conv1d_2[0][0]']               \n                                                                                                  \n conv1d_1 (Conv1D)              (None, 21, 128)      8320        ['dropout[0][0]']                \n                                                                                                  \n conv1d_3 (Conv1D)              (None, 21, 128)      8320        ['dropout_2[0][0]']              \n                                                                                                  \n max_pooling1d (MaxPooling1D)   (None, 10, 128)      0           ['conv1d_1[0][0]']               \n                                                                                                  \n max_pooling1d_1 (MaxPooling1D)  (None, 10, 128)     0           ['conv1d_3[0][0]']               \n                                                                                                  \n dropout_1 (Dropout)            (None, 10, 128)      0           ['max_pooling1d[0][0]']          \n                                                                                                  \n dropout_3 (Dropout)            (None, 10, 128)      0           ['max_pooling1d_1[0][0]']        \n                                                                                                  \n flatten (Flatten)              (None, 1280)         0           ['dropout_1[0][0]']              \n                                                                                                  \n flatten_1 (Flatten)            (None, 1280)         0           ['dropout_3[0][0]']              \n                                                                                                  \n dense (Dense)                  (None, 8)            10248       ['flatten[0][0]']                \n                                                                                                  \n dense_1 (Dense)                (None, 8)            10248       ['flatten_1[0][0]']              \n                                                                                                  \n concatenated_layer (Concatenat  (None, 16)          0           ['dense[0][0]',                  \n e)                                                               'dense_1[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 8)            136         ['concatenated_layer[0][0]']     \n                                                                                                  \n leaky_re_lu (LeakyReLU)        (None, 8)            0           ['dense_2[0][0]']                \n                                                                                                  \n dropout_4 (Dropout)            (None, 8)            0           ['leaky_re_lu[0][0]']            \n                                                                                                  \n dense_3 (Dense)                (None, 1)            9           ['dropout_4[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 168,481\nTrainable params: 168,481\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def compile_model(model):\n  model.compile(optimizer='adam', loss = tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n  return model\n# Function to get_score from the model given the training and test dataset\n\ndef get_score(model, X_train, X_test, y_train, y_test):\n  # patient early stopping\n#   es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n#   history = model.fit(X_train, y_train, epochs=10, validation_data = (X_test, y_test), verbose=0, callbacks=[es])\n  with tf.device(\"/gpu:0\"):\n      history = model.fit(X_train, y_train, epochs=30, batch_size = 2048, validation_data = (X_test, y_test), verbose=0)\n\n\n  # X_shape = X_train.shape\n  #X_train = np.expand_dims(X_train, axis=0)\n  # datagen.fit(X_train)\n  # fits the model on batches with real-time data augmentation:\n  # model.fit(X_train, y_train, batch_size=32,epochs=20)\n\n  train_acc_history = history.history['accuracy']\n  val_acc_history = history.history['val_accuracy']\n  # evaluate the model\n  _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n  _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n  return train_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:29.924358Z","iopub.execute_input":"2023-02-20T03:12:29.924729Z","iopub.status.idle":"2023-02-20T03:12:29.940370Z","shell.execute_reply.started":"2023-02-20T03:12:29.924692Z","shell.execute_reply":"2023-02-20T03:12:29.939676Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndata_bert = np.load('/kaggle/input/data21/data21_bert.npz')\npositive_bert = data_bert['positive']\nnegative_bert = data_bert['negative']\ndata_T5 = np.load('/kaggle/input/data21/data21_t5.npz')\npositive_T5 = data_T5['positive']\nnegative_T5 = data_T5['negative']\n\npositive_dataset = np.hstack((positive_bert, positive_T5))\nnegative_dataset = np.hstack((negative_bert, negative_T5))\nprint(negative_dataset.shape[0])\nX = np.vstack([positive_dataset, negative_dataset]) \np_label = np.ones(positive_dataset.shape[0])\nn_label = np.zeros(negative_dataset.shape[0])\nY = np.append(p_label,n_label,axis=0)\n\ndel data_bert\ndel positive_bert\ndel negative_bert\ndel data_T5\ndel positive_T5\ndel negative_T5\ndel positive_dataset\ndel negative_dataset\ngc.collect()\nprint(X.shape)\nprint(Y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:12:29.941350Z","iopub.execute_input":"2023-02-20T03:12:29.941715Z","iopub.status.idle":"2023-02-20T03:12:51.288411Z","shell.execute_reply.started":"2023-02-20T03:12:29.941679Z","shell.execute_reply":"2023-02-20T03:12:51.286555Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"5183\n(10027, 42, 1024)\n(10027,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nimport gc\nX_train, X_t, Y_train, Y_t = train_test_split( X, Y, test_size=0.05, random_state=42)\nfolds = StratifiedKFold(n_splits=10)\nscores = {}\nscores['train_acc'] = []\nscores['test_acc'] = []\nmax_test_acc = 0\nmax_mcc = 0\nX = X_train\nY = Y_train\nX_te = [X_t[:, :21], X_t[:, 21:]]\ny_true = Y_t\nfor train_index, test_index in folds.split(X,Y):\n    X_train, X_test, y_train, y_test = X[train_index], X[test_index], \\\n                                    Y[train_index], Y[test_index]\n    model = get_model()\n    model = compile_model(model)\n    X_train = [X_train[:, :21], X_train[:, 21:]]\n    X_test = [X_test[:, :21], X_test[:, 21:]]\n    train_acc, test_acc = get_score(model, X_train, X_test, y_train, y_test)\n    y_pred = model.predict(X_te) > 0.5\n    mcc = sklearn.metrics.matthews_corrcoef(y_true, y_pred)\n    print(\"test mcc: \", mcc)\n#     if test_acc > max_test_acc:\n    if mcc > max_mcc:\n        model.save('/kaggle/working/model1.h5')\n#         max_test_acc = test_acc\n        max_mcc = mcc\n    print(train_acc, test_acc)\n    scores['train_acc'].append(train_acc)\n    scores['test_acc'].append(test_acc)\n    del model\n    del X_train\n    del X_test\n    del y_train\n    del y_test\n    gc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-19T14:53:03.990430Z","iopub.execute_input":"2023-02-19T14:53:03.990817Z","iopub.status.idle":"2023-02-19T15:02:14.398218Z","shell.execute_reply.started":"2023-02-19T14:53:03.990780Z","shell.execute_reply":"2023-02-19T15:02:14.397088Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"16/16 [==============================] - 0s 9ms/step\ntest mcc:  0.5181850832761379\n0.9674521684646606 0.7513116598129272\n16/16 [==============================] - 0s 5ms/step\ntest mcc:  0.5555212969555163\n0.9245216846466064 0.7701993584632874\n16/16 [==============================] - 0s 5ms/step\ntest mcc:  0.5230288885028722\n0.9317545294761658 0.753410279750824\n16/16 [==============================] - 0s 4ms/step\ntest mcc:  0.561899478674152\n0.9611526131629944 0.7502623200416565\n16/16 [==============================] - 0s 5ms/step\ntest mcc:  0.5329389268538984\n0.8645590543746948 0.7712486982345581\n16/16 [==============================] - 0s 4ms/step\ntest mcc:  0.5728648075369001\n0.8788055777549744 0.7584033608436584\n16/16 [==============================] - 0s 5ms/step\ntest mcc:  0.5439277343573953\n0.9122827649116516 0.7626050710678101\n16/16 [==============================] - 0s 4ms/step\ntest mcc:  0.5272131666599241\n0.9550915956497192 0.7510504126548767\n16/16 [==============================] - 0s 4ms/step\ntest mcc:  0.5261596054038087\n0.9442435503005981 0.7689075469970703\n16/16 [==============================] - 0s 5ms/step\ntest mcc:  0.5068022704143864\n0.9538084864616394 0.743697464466095\n","output_type":"stream"}]},{"cell_type":"code","source":"y_true= Y_t\nnew_model = tf.keras.models.load_model('/kaggle/working/model1.h5')\nX_te = [X_t[:, :21], X_t[:, 21:]]\ny_pred = new_model.predict(X_te) > 0.5\nmcc =sklearn.metrics.matthews_corrcoef(y_true, y_pred)\nprint(mcc)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T15:02:14.400828Z","iopub.execute_input":"2023-02-19T15:02:14.401242Z","iopub.status.idle":"2023-02-19T15:02:15.053432Z","shell.execute_reply.started":"2023-02-19T15:02:14.401200Z","shell.execute_reply":"2023-02-19T15:02:15.052230Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"16/16 [==============================] - 0s 4ms/step\n0.5728648075369001\n","output_type":"stream"}]},{"cell_type":"code","source":"f1_score = sklearn.metrics.f1_score(y_true, y_pred)\nprint(\"f1 score: \",f1_score)\nacc = sklearn.metrics.accuracy_score(y_true, y_pred)\nprint(\"acc: \", acc)\nconfusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\nprint(\"confusion matrix: \",confusion_matrix)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TSNE plot\nfrom sklearn.manifold import TSNE\n\n# The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n# out some marginal improvements. NB: This takes almost an hour!\ntsne = TSNE(random_state=1, n_iter=15000, metric=\"cosine\")\nX_mid = X[:,11].reshape((10027,1024))\nprint(X_mid.shape)\nembs = tsne.fit_transform(X_mid)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T03:17:09.813184Z","iopub.execute_input":"2023-02-20T03:17:09.813606Z","iopub.status.idle":"2023-02-20T03:36:48.435790Z","shell.execute_reply.started":"2023-02-20T03:17:09.813550Z","shell.execute_reply":"2023-02-20T03:36:48.433741Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(10027, 1024)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:827: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n  FutureWarning,\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/4133294085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Add to dataframe for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nFS = (10, 8)\nfig, ax = plt.subplots(figsize=FS)\n# Make points translucent so we can visually identify regions with a high density of overlapping points\nax.scatter(embs[:, 0], embs[:, 1], alpha=.1);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}